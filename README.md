# Это проект созданный для кейса «Создание описание к видео по тексту» от Rutube на хакатоне Цифровой Прорыв сезон ИИ
------------------
Готовое решение вы можете посмотреть в представленном ноутбуке [**DG_Rutube.ipynb**](https://github.com/Plluxury/DG_Rutube/blob/main/DG_Rutube.ipynb)

# Обработка данных
Удаление стоп-слов, тайм кодов и мата(если он есть)

В качестве стоп слов, мы взяли файл предлагаемый в baseline решении 

# Описание и обоснование выбора используемых моделей
## Для суммаризации текста мы выбрали модель mbart_ru_sum_gazeta 

### Описание:
Данная модель представляет из себя портированную версию модели fairseq, которая в свою очередь является сверточной нейронно сетью (cnn) для машинного перевода. Например результат моделей основынах на fairseq в 9 раз быстрее традиционных рекуррентных нейронных сетей (rnn).

### Обоснование:
Для нашей задачи применение портированой fairseq модели подходит идеально так как в ней, в отличии от других cnn-моделей реализовани технология многоуровнего внимания, которая позволяет обращаться к различным частям текста в независимости от их расположения в нем. Одной из приоретных задач модели явялется пересказ, что нам и нужно. Также модель mbart_ru_sum_gazeta включает в себя mBART, который в свою очередь является автокодировщиком, предварительно обученым на крупномаштабных языковыхз датасетах. Обучение модели производится путем шумоподавления, которое представлет из себя преобразование нейроных последовательностей зашумленого текста в оригинальный.

### Справка:
fairseq - набор инструментов для моделирования последовательностей
сверточная нейронная сеть в nlp - слова(точки) в многомерном пространстве которые составляются в вектора из которых получается искомая матрица(предложение), информация хранится в многомерном пространстве до конца генерации
рекуррентная нейронная сеть - нейроны(слова) получают информацию от предыдущего слоя, соответственно влияет порядок входных данных, с течением времени информация теряеться
портирование - адаптация некоторой программы или её части, для того чтобы она работала в другой среде

## Для генерации описания к видео без звука **microsoft/phi-1_5**
### Описание: 
Модель представляет из себя языковую модель Трансформер с 1,3 миллиардами параметров. Она была обучена с использованием тех же источников данных, что и ее предшетсвеница phi-1 и дополненна новыми источниками данных, состоящим из различных синтетических текстов NLP.
Основными задачами модели являются ответы на вопросы и создание кода на python. В нашем коде она применена для первого. 

### Обоснование:
Данная модель использует такой патерн обучение как Transformer, под навазнием которого понимают архитектуру глубокого обучения, осонованную на параллельном механизме внимания. Главным отличием от рекурентых нейронных сетей является меньшее количество требуемого времени на обучение. Процесс обработки входного текста представляет из себя разбиение на n-граммы, которые представляется в виде токенов, которой в дальнейшем констекстуалезируется и с помощью параллельного механизма внимания позволяет выделять болле важные токены.

## Для перевода текста Helsinki-NLP/opus-mt-en-ru и Helsinki-NLP/opus-mt-ru-en 

### Описание: 
Модель как и предыдушая представляет из себя Трансформер с параллельным механизмом внимания, но дополненую моделью ALIGN. Модель ALIGN представляет из себя мультимодальная модель для работы как с фото так и с текстом. Также включает в себя два кодировщика один для фото и один для слов, в виде кодировщика для работы с текстом выступает модель BERT.

### Обоснование:
Так как времени было немного, а для решения нашей задачи нам были необходимы модели перевода, мы выбрали именно их. Одним из факторов выбора был то что в этой модели используется BERT потому что он учитывает окружающий контекст предложения и двухсторониий контекст входного токена, из-за чего модель лучше понимает многозначные слова, чт ов переводе встречается не так уж и редко.

### Справка: 
Мультимодальная модель - модель работающая с разными входными параметрами (видео и текст, аудио и текст).

# Метрики
Метрики каждой модели представлены в Google Colab notebook: [**DG_Rutube.ipynb**](https://github.com/Plluxury/DG_Rutube/blob/main/DG_Rutube.ipynb)

## Метрики на которы мы обращали внимание при выборе:

**BLEU** - алгоритм оценки качества текста, который был переведен с помощью ML-модели. Основная идея данной метрики, что чем ближе текст к человеческому, тем выше оценка метрики. Оценка произодится сравниванием полученных предложений с эталонными, после чего она усредняется.

**METEOR** - также является алгоритмом оценки качества текста полученного от модели, но уже с помощью n-грамм слов. В отличии от BLEU использует функции сопоставления синонимов. В сравнение имеет большую точность чем BLEU примерно на 10%.

**chr-f** - метрика для оценки машинного перевода, которая также использует n-граммы, но уже символо, а не слов. Применима когда нужно узнать точность для языков с высокой морфологией, что для метрик n-грамм по словам является проблемой. Она также слабо зависит от языка или токенизации

**Коэфициент Жаккара** - биннарная мера сходства, является показателем сходства сравниваемых объектов. Оценивается в диапазоне от 0 до 1.

**Значение метрик для сгенерированных описаний по тренировочным данным**
**Для получений описаний тренировочных данных использовался i5 7600kf**

| Метрика | Значение |
|----------------|---------|
| METEOR | 0.089 |
| Коэффициент Жаккара | 0.41 | 
| Bleu | 1.21 | 
| Infernce | 8 секунд |

*Метрики считались на всех 500 записях
